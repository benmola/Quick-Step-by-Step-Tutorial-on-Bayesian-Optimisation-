{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a54e11b-263e-46b8-8f32-440769ff1500",
   "metadata": {},
   "source": [
    "# Bayesian Optimization: A Comprehensive Guide for Researchers\n",
    "---\n",
    "Bayesian Optimization (BO) is a powerful and efficient method for solving optimization problems where the objective function $f(\\mathbf{x})$ is expensive to evaluate, lacks an analytical expression, and is typically treated as a black-box function <sup>[1][2]</sup>.. This scenario is common in machine learning, particularly in hyperparameter tuning, where evaluating model performance for a given hyperparameter configuration can be computationally costly. In this guide, we delve into the theoretical foundations of BO, its key components, and its practical application to hyperparameter optimization, drawing insights from <sup>[1]</sup>. and established literature<sup>[3]</sup>.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/bo_intro_.png\" alt=\"Bayesian Optimization Overview Animation\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction to Bayesian Optimization\n",
    "\n",
    "In machine learning, many optimization problems involve finding the maximum (or minimum) of a black-box function $f(\\mathbf{x})$, formally expressed as:\n",
    "$$\\mathbf{x}^* = \\arg\\max_{\\mathbf{x} \\in \\mathcal{X}} f(\\mathbf{x}),$$\n",
    "where $\\mathcal{X}$ is the search space, and $f(\\mathbf{x})$ lacks a closed-form expression or derivatives. Traditional methods like grid search or random search <sup>[2]</sup>.are feasible when evaluations are inexpensive, but they become impractical when each evaluation is costly—e.g., training a deep neural network, probe drilling for oil, or evaluating drug candidates. Bayesian Optimization addresses this challenge by minimizing the number of function evaluations required to locate the global optimum.\n",
    "\n",
    "BO operates by modeling the objective function with a **surrogate model**, typically a Gaussian Process (GP), which provides a probabilistic estimate of $f(\\mathbf{x})$. This model is iteratively refined using observed data, and an **acquisition function** guides the selection of the next evaluation point by balancing **exploration** (sampling uncertain regions) and **exploitation** (sampling promising regions based on current predictions). Wu et al. (2019) emphasize BO's effectiveness for hyperparameter tuning, where it outperforms traditional methods like grid search in both efficiency and accuracy.\n",
    "\n",
    "Traditional optimization techniques, such as Newton’s method or gradient descent, rely on derivatives and are inapplicable here due to the absence of an explicit form for $f(\\mathbf{x})$. BO, rooted in Bayes’ theorem, combines prior beliefs about $f(\\mathbf{x})$ with sampled evidence to iteratively refine the posterior distribution, making it ideal for such problems.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/bo_intro_2d_comparison.png\" alt=\"BO 2D Search Comparison\" width=\"600\"/>\n",
    "    <p style=\"font-style: italic;\">Comparison of Bayesian Optimization with grid and random search on a 2D black-box function, highlighting BO’s targeted efficiency.</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## 2. Gaussian Processes as the Surrogate Model\n",
    "\n",
    "The surrogate model in BO is most commonly a **Gaussian Process (GP)**, a flexible, non-parametric framework for modeling distributions over functions. A GP defines a prior over $f(\\mathbf{x})$, specified by a mean function $m(\\mathbf{x})$ and a covariance function $k(\\mathbf{x}, \\mathbf{x}')$:\n",
    "$$f(\\mathbf{x}) \\sim \\mathcal{GP}(m(\\mathbf{x}), k(\\mathbf{x}, \\mathbf{x}')).$$\n",
    "\n",
    "For simplicity, the mean is often assumed to be zero ($m(\\mathbf{x}) = 0$), and the covariance function (or kernel) encodes assumptions about the function's properties, such as smoothness. A widely used kernel is the squared exponential:\n",
    "$$k(\\mathbf{x}_i, \\mathbf{x}_j) = \\exp\\left(-\\frac{1}{2} \\|\\mathbf{x}_i - \\mathbf{x}_j\\|^2\\right),$$\n",
    "which assumes that points closer in the input space have more similar function values, reflecting a smooth function. The GP’s flexibility and suitability as a prior due to its ability to model uncertainty effectively.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/gp_plot.png\" alt=\"Gaussian Process Surrogate Model\" width=\"500\"/>\n",
    "    <p style=\"font-style: italic;\">Gaussian Process surrogate model with initial samples, showing mean prediction and 95% confidence interval.</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1 Posterior Update in Gaussian Processes\n",
    "\n",
    "Given observed data $\\mathcal{D}_{1:t-1} = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{t-1}$, where $y_i = f(\\mathbf{x}_i) + \\epsilon_i$ and $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma_n^2)$ is Gaussian noise, the GP provides a posterior distribution over $f(\\mathbf{x})$ at any point $\\mathbf{x}$. This posterior remains Gaussian:\n",
    "$$f(\\mathbf{x}) \\mid \\mathcal{D}_{1:t-1} \\sim \\mathcal{N}(\\mu_{t-1}(\\mathbf{x}), \\sigma_{t-1}^2(\\mathbf{x})),$$\n",
    "with:\n",
    "$$\\mu_{t-1}(\\mathbf{x}) = \\mathbf{k}^\\top (\\mathbf{K} + \\sigma_n^2 \\mathbf{I})^{-1} \\mathbf{y},$$\n",
    "$$\\sigma_{t-1}^2(\\mathbf{x}) = k(\\mathbf{x}, \\mathbf{x}) - \\mathbf{k}^\\top (\\mathbf{K} + \\sigma_n^2 \\mathbf{I})^{-1} \\mathbf{k},$$\n",
    "where:\n",
    "- $\\mathbf{k} = [k(\\mathbf{x}, \\mathbf{x}_1), \\dots, k(\\mathbf{x}, \\mathbf{x}_{t-1})]^\\top$ is the covariance vector between $\\mathbf{x}$ and observed points,\n",
    "- $\\mathbf{K}$ is the covariance matrix with entries $K_{ij} = k(\\mathbf{x}_i, \\mathbf{x}_j)$,\n",
    "- $\\mathbf{y} = [y_1, \\dots, y_{t-1}]^\\top$ is the vector of observed values,\n",
    "- $\\sigma_n^2$ is the noise variance.\n",
    "\n",
    "The posterior mean $\\mu_{t-1}(\\mathbf{x})$ predicts the function value, while the variance $\\sigma_{t-1}^2(\\mathbf{x})$ quantifies uncertainty, both of which are critical for guiding the optimization process. As depicted in Wu et al.'s Fig. 1, variance is low near observed points and high in unexplored regions, enabling BO to adaptively refine its search.\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/gp_posterior_update.gif\" alt=\"GP Posterior Update Animation\" width=\"600\"/>\n",
    "    <p style=\"font-style: italic;\">Animation of the Gaussian Process posterior updating as new samples are added, reducing uncertainty over iterations.</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Acquisition Functions\n",
    "\n",
    "The **acquisition function** $u(\\mathbf{x} \\mid \\mathcal{D}_{1:t-1})$ determines the next point to evaluate by maximizing a utility criterion:\n",
    "$$\\mathbf{x}_t = \\arg\\max_{\\mathbf{x} \\in \\mathcal{X}} u(\\mathbf{x} \\mid \\mathcal{D}_{1:t-1}).$$\n",
    "It balances exploration (high uncertainty, large $\\sigma(\\mathbf{x})$) and exploitation (high predicted value, large $\\mu(\\mathbf{x})$). Wu et al. (2019) explore three common acquisition functions: Probability of Improvement (PI), Expected Improvement (EI), and GP Upper Confidence Bound (GP-UCB).\n",
    "\n",
    "---\n",
    "\n",
    "### 3.1 Probability of Improvement (PI)\n",
    "\n",
    "The **Probability of Improvement (PI)** measures the probability that $f(\\mathbf{x})$ exceeds the current best observed value $f(\\mathbf{x}^+)$, where $\\mathbf{x}^+ = \\arg\\max_{\\mathbf{x}_i \\in \\mathbf{x}_{1:t-1}} f(\\mathbf{x}_i)$:\n",
    "$$\\mathrm{PI}(\\mathbf{x}) = P(f(\\mathbf{x}) \\geq f(\\mathbf{x}^+) \\mid \\mathcal{D}_{1:t-1}) = \\Phi\\left( \\frac{\\mu(\\mathbf{x}) - f(\\mathbf{x}^+)}{\\sigma(\\mathbf{x})} \\right),$$\n",
    "where $\\Phi(\\cdot)$ is the standard normal cumulative distribution function (CDF).\n",
    "\n",
    "PI is intuitive but greedy, favoring exploitation near $\\mathbf{x}^+$, which can trap it in local optima <sup>[1]</sup>. To mitigate this, an exploration parameter $\\varepsilon$ can be introduced:\n",
    "$$\\mathrm{PI}_\\varepsilon(\\mathbf{x}) = \\Phi\\left( \\frac{\\mu(\\mathbf{x}) - f(\\mathbf{x}^+) - \\varepsilon}{\\sigma(\\mathbf{x})} \\right),$$\n",
    "requiring a significant improvement. However, PI still struggles with global exploration in multimodal functions.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/pi_plot.png\" alt=\"Probability of Improvement\" width=\"500\"/>\n",
    "    <p style=\"font-style: italic;\">Probability of Improvement (PI) acquisition function, highlighting the next point selected.</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### 3.2 Expected Improvement (EI)\n",
    "\n",
    "The **Expected Improvement (EI)** quantifies the expected improvement over $f(\\mathbf{x}^+)$:\n",
    "$$\\mathrm{EI}(\\mathbf{x}) = \\mathbb{E} \\left[ \\max(f(\\mathbf{x}) - f(\\mathbf{x}^+), 0) \\mid \\mathcal{D}_{1:t-1} \\right].$$\n",
    "Under the GP posterior, EI has a closed-form expression:\n",
    "$$\\mathrm{EI}(\\mathbf{x}) = \n",
    "\\begin{cases}\n",
    "(\\mu(\\mathbf{x}) - f(\\mathbf{x}^+) - \\xi) \\Phi(Z) + \\sigma(\\mathbf{x}) \\phi(Z) & \\text{if } \\sigma(\\mathbf{x}) > 0, \\\\\n",
    "0 & \\text{if } \\sigma(\\mathbf{x}) = 0,\n",
    "\\end{cases}$$\n",
    "where:\n",
    "$$Z = \\frac{\\mu(\\mathbf{x}) - f(\\mathbf{x}^+) - \\xi}{\\sigma(\\mathbf{x})},$$\n",
    "and $\\phi(\\cdot)$ is the standard normal probability density function (PDF). The parameter $\\xi \\geq 0$ adjusts the exploration-exploitation trade-off; <sup>[1]</sup>.recommend $\\xi = 0.01$ as a default.\n",
    "\n",
    "EI balances exploitation (via $(\\mu(\\mathbf{x}) - f(\\mathbf{x}^+) - \\xi) \\Phi(Z)$) and exploration (via $\\sigma(\\mathbf{x}) \\phi(Z)$), making it less prone to local optima than PI. In <sup>[1]</sup>. EI finds the global optimum after five iterations, outperforming PI.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/ei_plot.png\" alt=\"Expected Improvement\" width=\"500\"/>\n",
    "    <p style=\"font-style: italic;\">Expected Improvement (EI) acquisition function, highlighting the next point selected.</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### 3.3 GP Upper Confidence Bound (GP-UCB)\n",
    "\n",
    "The **GP Upper Confidence Bound (GP-UCB)** explicitly balances mean and uncertainty:\n",
    "$$\\mathrm{UCB}(\\mathbf{x}) = \\mu(\\mathbf{x}) + \\kappa \\sigma(\\mathbf{x}),$$\n",
    "where $\\kappa > 0$ controls the trade-off. Larger $\\kappa$ values emphasize exploration, while smaller values favor exploitation.\n",
    "\n",
    "GP-UCB also finds the global optimum <sup>[1][2]</sup>, but requires tuning $\\kappa$, adding complexity. EI’s simplicity and robust performance make it the preferred choice in their experiments.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/gp_ucb_plot.png\" alt=\"GP Upper Confidence Bound\" width=\"500\"/>\n",
    "    <p style=\"font-style: italic;\">GP Upper Confidence Bound (GP-UCB) acquisition function, highlighting the next point selected.</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 4. The Bayesian Optimization Algorithm\n",
    "\n",
    "The BO algorithm iteratively refines the surrogate model and selects evaluation points:\n",
    "1. **Initialize**: Start with a small set of random points (e.g., 5 samples) to form $\\mathcal{D}_{1:0}$.\n",
    "2. **Fit the GP**: Compute the posterior $\\mu_{t-1}(\\mathbf{x})$ and $\\sigma_{t-1}^2(\\mathbf{x})$ using $\\mathcal{D}_{1:t-1}$.\n",
    "3. **Optimize the Acquisition Function**: Select:\n",
    "   $$\\mathbf{x}_t = \\arg\\max_{\\mathbf{x} \\in \\mathcal{X}} u(\\mathbf{x} \\mid \\mathcal{D}_{1:t-1}).$$\n",
    "4. **Evaluate**: Compute $y_t = f(\\mathbf{x}_t) + \\epsilon_t$.\n",
    "5. **Update**: Augment $\\mathcal{D}_{1:t} = \\mathcal{D}_{1:t-1} \\cup \\{(\\mathbf{x}_t, y_t)\\}$.\n",
    "6. **Repeat**: Continue until a stopping criterion (e.g., maximum iterations or convergence) is met.\n",
    "\n",
    "This process, detailed in <sup>[1]</sup>, leverages the GP’s computational efficiency to minimize costly evaluations of $f$, distinguishing it from gradient-based methods requiring explicit derivatives.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/bo_ucb_animation.gif\" alt=\"BO Algorithm Animation with GP-UCB\" width=\"600\"/>\n",
    "    <p style=\"font-style: italic;\">Animation of Bayesian Optimization using GP-UCB over 10 iterations, demonstrating adaptive exploration and exploitation.</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Application to Hyperparameter Optimization\n",
    "\n",
    "Hyperparameter optimization is a key application of BO, as validated by  across different machine learning models like Random Forests and Neural Networks <sup>[1][2][3]</sup>.\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"Images/comparison_plot.png\" alt=\"Hyperparameter Tuning Comparison\" width=\"500\"/>\n",
    "    <p style=\"font-style: italic;\">Comparison of BO (GP-UCB), grid search, and random search in a simulated hyperparameter tuning task.</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 5.1 Random Forests\n",
    "\n",
    "Random Forests are ensemble classifiers that aggregate decisions from multiple trees. In, <sup>[1]</sup>. optimize:\n",
    "- Number of trees,\n",
    "-  Number of features per split.\n",
    "\n",
    "On seven UCI datasets (e.g., \"Car evaluation\"), BO improved accuracy (e.g., 89.56% to 90.68%) with fewer evaluations than grid search, which exhaustively tests combinations <sup>[1][2]</sup>.\n",
    "\n",
    "\n",
    "\n",
    "### 5.2 Neural Networks\n",
    "\n",
    "For **Convolutional Neural Networks (CNNs)** and **Recurrent Neural Networks (RNNs)**, BO tunes:\n",
    "- Learning rate \n",
    "- Batch size \n",
    "- Learning rate decay\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1] Wu, J., et al. \"Hyperparameter Optimization for Machine Learning Models Based on Bayesian Optimization.\" *Journal of Electronic Science and Technology*, vol. 17, no. 1, March 2019.\n",
    "\n",
    "[2] Bergstra, J., & Bengio, Y. \"Random search for hyper-parameter optimization.\" *Journal of Machine Learning Research*, vol. 13, 2012.\n",
    "\n",
    "[3] Jones, D. R. \"A taxonomy of global optimization methods based on response surfaces.\" *Journal of Global Optimization*, vol. 21, no. 4, 2001."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814686f-3162-4e1c-818a-233040aae1b1",
   "metadata": {},
   "source": [
    "## Bayesian Optimization Libraries\n",
    "\n",
    "As we transition from the theoretical foundations of Bayesian Optimization to practical implementation, it’s essential to introduce the tools that enable us to apply BO effectively. Numerous libraries and packages exist for performing BO, each with unique features tailored to different use cases in hyperparameter optimization and beyond. Providing a comprehensive review of all BO libraries is beyond the scope of this tutorial. Instead, this section highlights a selection of commonly used libraries, focusing on those that are accessible, well-documented, and capable of replicating the experiments for tuning machine learning models such as Random Forests, Neural Networks, and Multi-Grained Cascade Forests (gcForest). Below, I outline key libraries, their purposes, and a brief setup context, setting the stage for code examples later in this notebook.\n",
    "\n",
    "---\n",
    "\n",
    "### Common Bayesian Optimization Libraries\n",
    "\n",
    "Here’s a curated list of popular BO libraries, with brief descriptions:\n",
    "\n",
    "1. **[Scikit-learn](https://scikit-learn.org/)**  \n",
    "   While primarily a general-purpose machine learning library, Scikit-learn includes tools like `GridSearchCV` and `RandomizedSearchCV` for basic hyperparameter tuning. For BO, it serves as a foundation by providing machine learning models (e.g., Random Forests) that can be optimized using other BO libraries.\n",
    "\n",
    "2. **[Scikit-Optimize (skopt)](https://scikit-optimize.github.io/)**  \n",
    "   A lightweight library built on top of Scikit-learn, Scikit-Optimize implements BO with Gaussian Processes (GPs). It’s user-friendly, integrates seamlessly with Scikit-learn models, and supports acquisition functions like Expected Improvement (EI). It’s an excellent starting point for beginners and aligns with the simplicity.\n",
    "\n",
    "3. **[Optuna](https://optuna.org/)**  \n",
    "   A flexible, modern BO framework that supports tree-structured Parzen estimators (TPE) alongside GPs. Optuna is highly customizable, efficient for large-scale optimization, and suitable for tuning Neural Networks as demonstrated in the MNIST and CIFAR-10 experiments.\n",
    "\n",
    "4. **[Hyperopt](https://hyperopt.github.io/hyperopt/)**  \n",
    "   A Python library focused on BO with TPE as its default method. Hyperopt is versatile, supports distributed optimization, and is well-suited for tuning complex models like those in Wu et al.’s Neural Network experiments.\n",
    "\n",
    "5. **[Ray Tune](https://docs.ray.io/en/latest/tune/index.html)**  \n",
    "   Part of the Ray ecosystem, Ray Tune provides scalable BO with support for various search algorithms (e.g., BOHB, HyperBand). It’s ideal for distributed hyperparameter tuning, making it relevant for computationally expensive models like deep Neural Networks.\n",
    "\n",
    "6. **[Talos](https://autonomio.github.io/talos/)**  \n",
    "   Designed specifically for Keras models, Talos integrates BO for hyperparameter tuning of Neural Networks. It’s a practical choice for deep learning applications.\n",
    "\n",
    "7. **[BayesianOptimization](https://github.com/fmfn/BayesianOptimization)**  \n",
    "   A pure Python implementation of BO with GPs, offering a simple interface for optimizing black-box functions. It’s lightweight and directly applicable to the Random Forest and gcForest tuning scenarios.\n",
    "\n",
    "8. **[Metric Optimization Engine (MOE)](https://github.com/Yelp/MOE)**  \n",
    "   Developed by Yelp, MOE is a scalable BO framework with a focus on multi-objective optimization. It uses GPs and is suitable for advanced research applications.\n",
    "\n",
    "9. **[Spearmint](https://github.com/HIPS/Spearmint)**  \n",
    "   An early BO library using GPs, Spearmint is well-regarded for its robustness. Though less actively maintained, it’s historically significant and capable of handling the experiments in this tutorial.\n",
    "\n",
    "10. **[GPyOpt](http://sheffieldml.github.io/GPyOpt/)**  \n",
    "    Built on the GPy library for Gaussian Processes, GPyOpt provides a modular BO implementation. It’s academically oriented, supports various acquisition functions, and is suitable for detailed GP-based optimization as described in Section 3.1 of Wu et al. (2019).\n",
    "\n",
    "11. **[SigOpt](https://sigopt.com/)**  \n",
    "    A commercial BO platform with a Python API, SigOpt offers advanced features like multi-metric optimization. It’s a premium option for enterprise-level tuning.\n",
    "\n",
    "12. **[Fabolas](https://github.com/automl/Fabolas)**  \n",
    "    An extension of BO that accounts for training cost, Fabolas is efficient for large datasets and models like those in Wu et al.’s experiments.\n",
    "\n",
    "13. **[BoTorch](https://botorch.org/)**  \n",
    "    A PyTorch-based BO library, BoTorch provides state-of-the-art GP modeling and acquisition functions. It’s ideal for researchers integrating BO with deep learning frameworks.\n",
    "\n",
    "14. **[pyGPGO](https://github.com/josejimenezluna/pyGPGO)**  \n",
    "    A simple, flexible BO library using GPs, pyGPGO is lightweight and easy to extend for custom applications.\n",
    "\n",
    "\n",
    "    For this tutorial, I’ll focus on **GPyOpt** due to its simplicity, compatibility with Scikit-learn models, and alignment with the Gaussian Process-based approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5408ef9e-d064-4e67-8130-8898d754128b",
   "metadata": {},
   "source": [
    "## Some Useful Links!\n",
    "\n",
    "---\n",
    "1. **Hyperparameters Selection Using Bayesian Optimization**  \n",
    "   [https://www.linkedin.com/pulse/hyperparameters-selection-using-bayesian-optimization-tuta-botero/](https://www.linkedin.com/pulse/hyperparameters-selection-using-bayesian-optimization-tuta-botero/)\n",
    "\n",
    "2. **Bayesian Optimization Tutorial**  \n",
    "   [http://krasserm.github.io/2018/03/21/bayesian-optimization/](http://krasserm.github.io/2018/03/21/bayesian-optimization/)\n",
    "\n",
    "3. **GPyOpt Tutorial**  \n",
    "   [https://www.blopig.com/blog/wp-content/uploads/2019/10/GPyOpt-Tutorial1.html](https://www.blopig.com/blog/wp-content/uploads/2019/10/GPyOpt-Tutorial1.html)\n",
    "\n",
    "4. **Gaussian Processes Tutorial**  \n",
    "   [http://krasserm.github.io/2018/03/19/gaussian-processes/](http://krasserm.github.io/2018/03/19/gaussian-processes/)\n",
    "\n",
    "5. **Sargent Centre BO Summer School 2024 (GitHub)**  \n",
    "   [https://github.com/joelpaulson/Sargent_Centre_BO_Summer_School_2024](https://github.com/joelpaulson/Sargent_Centre_BO_Summer_School_2024)\n",
    "\n",
    "6. **Great Lakes PSE Workshop 2023 (GitHub)**  \n",
    "   [https://github.com/joelpaulson/Great_Lakes_PSE_Workshop_2023/tree/main](https://github.com/joelpaulson/Great_Lakes_PSE_Workshop_2023/tree/main)\n",
    "\n",
    "7. **Bayesian Optimization on Neural Network Hyperparameters**  \n",
    "   [https://medium.com/@5180_90108/bayesian-optimization-on-neural-network-hyperparameters-fb070e4aeb0b](https://medium.com/@5180_90108/bayesian-optimization-on-neural-network-hyperparameters-fb070e4aeb0b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a9b79-14a2-4917-a900-12ada60b9ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
